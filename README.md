
##  做这个的起因还是英文口语对话功能，之前对这个不太感冒，但是对话几轮后，我觉得她还是很有意义的，至少可能遇不到口语标准的英语老师的话，可以和她对话，哈哈。
###  实时语音模型就我目前了解来看主要分端到端和语音合成两大种方式，两种都体验了下，肯定还是端到端的效果要好一些的，但语音合成的也还是不错的。

本项目的整体流程架构如下：
![img.png](/img.png)
## 🔍 项目简介

**AI Voice Web** 是一个专注于**实时语音交互体验**的 Web 前端项目，集成语音识别、实时 WebSocket 通信、语音合成播放等能力，适用于多种 AI 对话场景，如：

- 智能助理
- 教育问答
- 多模态客服
- AI 陪聊机器人

> 当前版本已对接 **字节跳动豆包模型（Doubao）**，未来将支持 GPT-4、Claude、Gemini 等主流大模型接口的灵活切换。

---

## ✨ 功能亮点

- 🎤 实时麦克风录音 + 波形可视化（支持移动端）
- 🔁 WebSocket 双向流式音频通信
- 🧠 AI 实时语音识别 + 文本生成
- 🔊 语音合成播放（支持 AudioContext 兼容性）
- 💬 字幕 / 消息记录模式切换
- 📱 移动端 iOS 浏览器兼容优化

---

## 📦 技术栈

- **前端框架**：Vue 2  后续将更新vue3版本，因为官方没有react版本，飞书群也基本没人回复。。
- **音频处理**：Web Audio API
- **通信协议**：WebSocket（支持 PCM 音频推送）
- **AI 模型**：豆包（Doubao），后续支持 GPT-4、Claude、百川等

---

## 🚧 未来规划

- ✅ 多模型适配（GPT / Claude / 百川 / 通义）
- ✅ 语音中断、打断重问机制
- ⏳ 多角色支持 

---




